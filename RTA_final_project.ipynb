{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75af87f8",
   "metadata": {},
   "source": [
    "## Real Time Analytics Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a19fbb",
   "metadata": {},
   "source": [
    "<b> CryptoStreamLab: Real-Time Analysis of Cryptocurrency Markets Using Streaming Data </b> \\\n",
    "An Exploration of Real-Time Price and Volume Analysis with Spark, Kafka, and Streamlit for Enhanced Trading Strategies "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3848fe8b",
   "metadata": {},
   "source": [
    "<b> Author:\\\n",
    "    1. Cuong Vo - 131116\\\n",
    "    2. Trang Linh Nguyen - 131036\\\n",
    "    3. Aisel Akhmedova - 131008 </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d5a1fc",
   "metadata": {},
   "source": [
    "Tech Stack:\\\n",
    "    **1. Spark:** 3.5.0\\\n",
    "    **2. Python:** 3.10.12\\\n",
    "    **3. OS:** WSL Linux\\\n",
    "    **4. Streamlit:** \\\n",
    "    **5. Scala:** 2.12.18\\\n",
    "    **6. Java OpenJDK 64-Bit Server VM:** 11.0.25 \\\n",
    "    **7. Spark-submit:** org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc6bbed",
   "metadata": {},
   "source": [
    "## Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9677b1",
   "metadata": {},
   "source": [
    "## Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c2d266",
   "metadata": {},
   "source": [
    "The dataset consists of real-time cryptocurrency market data streamed from Binance. Each record includes the following fields:\n",
    "\n",
    "- **Ticker**: The symbol representing the cryptocurrency pair (e.g., BTCUSDT).\n",
    "- **Timestamp**: The date and time when the data was recorded.\n",
    "- **Open**: The opening price of the cryptocurrency for the given time interval.\n",
    "- **Close**: The closing price of the cryptocurrency for the given time interval.\n",
    "- **Price**: The current price at the time of data capture.\n",
    "- **Volume**: The total trading volume of the cryptocurrency during the interval.\n",
    "\n",
    "This data enables real-time analysis of price movements and trading activity for various cryptocurrencies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393f9117",
   "metadata": {},
   "source": [
    "## Kafka Server setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce6dbb3",
   "metadata": {},
   "source": [
    "Kafka Server is created on <b>localhost:9092</b> on WSL Linux Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582b8e51",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "$ sudo systemctl daemon-reload\n",
    "$ sudo systemctl start zookeeper\n",
    "$ sudo systemctl start kafka"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209e6559",
   "metadata": {},
   "source": [
    "To check status of Kafka Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b68a70",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "$ sudo systemctl status kafka "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d5c25b",
   "metadata": {},
   "source": [
    "## Streaming Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8a2d70",
   "metadata": {},
   "source": [
    "### Create Kafka topic\n",
    "In this part, using Linux to create Kafka topic name StreamQuant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68ec7a2",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "$ cd /usr/local/kafka \n",
    "$ bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --topic StreamQuant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b0b853",
   "metadata": {},
   "source": [
    "Check for topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e5f114",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "$ bin/kafka-topics.sh --list --bootstrap-server localhost:9092"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d527df6d",
   "metadata": {},
   "source": [
    "### Create Kafka Procedure\n",
    "In this part, combined with the API key from Binance, we pull the data from Binance and send it to Kakfa producer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50058ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from binance.client import Client\n",
    "from kafka import KafkaProducer\n",
    "import json\n",
    "import time\n",
    "\n",
    "#  using API keys\n",
    "api_key = 'giuBTEvNmtfaSuPpCZfmF7uXzRYfKzk7sAwC4ezjB3KbfGLS30UnQMDxcxs15WSB'\n",
    "api_secret = 'SOmHSWFBuTa20grpf8r87c9qm9tym1oHkjktpu4mIwB9L08qvXW4W9HK7FSt1y6o'\n",
    "\n",
    "client = Client(api_key, api_secret)\n",
    "\n",
    "def get_historical_data(symbol, interval, lookback):\n",
    "    \"\"\"\n",
    "    Fetch historical data from Binance for a given symbol and interval.\n",
    "    :param symbol: The trading pair symbol (e.g., 'BTCUSDT').\n",
    "    :param interval: The time interval for the data (e.g., '1m', '5m', '1h', '1d').\n",
    "    :param lookback: The lookback period for the data (e.g., '1 day ago UTC', '1 hour ago UTC').\n",
    "    \"\"\"\n",
    "    try:\n",
    "        klines = client.get_historical_klines(symbol, interval, lookback)\n",
    "        return klines\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {symbol}: {e}\")\n",
    "        return None\n",
    "    \n",
    "producer = KafkaProducer(\n",
    "    bootstrap_servers='localhost:9092',  # Replace with your Kafka broker if different\n",
    "    value_serializer=lambda v: json.dumps(v).encode('utf-8')  # Serialize to JSON bytes\n",
    ")\n",
    "\n",
    "topic = 'StreamQuant'\n",
    "\n",
    "i = 0\n",
    "\n",
    "keys = [\"timestamp\", \"open\", \"high\", \"low\", \"close\", \"volume\"]\n",
    "\n",
    "while True:\n",
    "    i +=1\n",
    "    binance_data = get_historical_data('BTCUSDT', '1m', '1 minute ago UTC')\n",
    "    values = [int(binance_data[0][0])] + [float(x) for x in binance_data[0][1:]]\n",
    "    data_dict = dict(zip(keys, values))\n",
    "    producer.send(topic, value=data_dict)\n",
    "    print(f\"Sent {topic} - {i}: {data_dict}\")\n",
    "    time.sleep(60)  # Sleep for 1 minute before fetching the next data point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a5efd3",
   "metadata": {},
   "source": [
    "Run Producer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f8b660",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "$ python3 binance_producer.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc1ae02",
   "metadata": {},
   "source": [
    "### Create Kafka Consumer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e1de83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, DoubleType, StructField, LongType\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "spark = SparkSession.builder.appName(\"StreamQuant\").getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "schema = StructType([\n",
    "  StructField('timestamp', LongType()),\n",
    "  StructField('open', DoubleType()),\n",
    "  StructField('high', DoubleType()),\n",
    "  StructField('low', DoubleType()),\n",
    "  StructField('close', DoubleType()),\n",
    "  StructField('volume', DoubleType())\n",
    "])\n",
    "\n",
    "df_raw = spark.readStream.format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"localhost:9092\") \\\n",
    "    .option(\"subscribe\", \"StreamQuant\") \\\n",
    "    .option(\"startingOffsets\", \"latest\") \\\n",
    "    .load()\n",
    "\n",
    "df_raw = df_raw.selectExpr(\"CAST(value AS STRING)\")\n",
    "\n",
    "df_raw = df_raw.withColumn(\"value\", F.from_json(df_raw.value, schema))\\\n",
    "    .select(\"value.*\")  \n",
    "\n",
    "df_raw = df_raw.withColumn(\"datetime\", F.from_unixtime(F.col(\"timestamp\") / 1000))\n",
    "\n",
    "df_raw.writeStream \\\n",
    " .format(\"parquet\") \\\n",
    " .option(\"path\", \"/tmp/stream_output/\") \\\n",
    " .option(\"checkpointLocation\", \"/tmp/stream_checkpoint/\") \\\n",
    " .outputMode(\"append\") \\\n",
    " .start() \\\n",
    " .awaitTermination()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13ef28b",
   "metadata": {},
   "source": [
    "Running Consumer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38aa00c2",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "$ spark-submit --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0 ~/Realtime_Analytics/quant_consumer.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ed4c25",
   "metadata": {},
   "source": [
    "## Trading Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a2dd1d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc1cf767",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce067785",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "st.set_page_config(page_title=\"📈 Real-Time Trading Dashboard\", layout=\"wide\")\n",
    "st.title(\"📊 Real-Time Trading with Candlestick, EMA, RSI & Signals\")\n",
    "\n",
    "DATA_DIR = \"/tmp/stream_output/\"\n",
    "# Refresh every 65 seconds\n",
    "REFRESH_INTERVAL = 65\n",
    "\n",
    "chart_placeholder = st.empty()\n",
    "\n",
    "def load_data():\n",
    "    files = [f for f in os.listdir(DATA_DIR) if f.endswith(\".parquet\")]\n",
    "    if not files:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df = pd.concat([pd.read_parquet(os.path.join(DATA_DIR, f)) for f in files])\n",
    "    return df\n",
    "\n",
    "def compute_indicators(df):\n",
    "    df[\"EMA_10\"] = df[\"close\"].ewm(span=10, adjust=False).mean()\n",
    "    df[\"EMA_20\"] = df[\"close\"].ewm(span=20, adjust=False).mean()\n",
    "    df[\"EMA_50\"] = df[\"close\"].ewm(span=50, adjust=False).mean()\n",
    "\n",
    "    delta = df[\"close\"].diff()\n",
    "    gain = delta.clip(lower=0)\n",
    "    loss = -delta.clip(upper=0)\n",
    "    avg_gain = gain.rolling(window=14).mean()\n",
    "    avg_loss = loss.rolling(window=14).mean()\n",
    "    rs = avg_gain / avg_loss\n",
    "    df[\"RSI\"] = 100 - (100 / (1 + rs))\n",
    "\n",
    "    # Generate basic Buy/Sell signals\n",
    "    df[\"signal\"] = np.where((df[\"RSI\"] < 30) & (df[\"close\"] > df[\"EMA_10\"]), \"Buy\",\n",
    "                     np.where((df[\"RSI\"] > 70) & (df[\"close\"] < df[\"EMA_10\"]), \"Sell\", \"Hold\"))\n",
    "    \n",
    "    df[\"prev_EMA_20\"] = df[\"EMA_20\"].shift(1)\n",
    "    df[\"prev_EMA_50\"] = df[\"EMA_50\"].shift(1)\n",
    "\n",
    "    crossover_buy = (df[\"EMA_20\"] > df[\"EMA_50\"]) & (df[\"prev_EMA_20\"] <= df[\"prev_EMA_50\"])\n",
    "    crossover_sell = (df[\"EMA_20\"] < df[\"EMA_50\"]) & (df[\"prev_EMA_20\"] >= df[\"prev_EMA_50\"])\n",
    "\n",
    "    df.loc[crossover_buy, \"signal\"] = \"Buy\"\n",
    "    df.loc[crossover_sell, \"signal\"] = \"Sell\"\n",
    "\n",
    "    return df\n",
    "\n",
    "def plot_price_chart(df):\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Candlestick\n",
    "    fig.add_trace(go.Candlestick(\n",
    "        x=df[\"datetime\"],\n",
    "        open=df[\"open\"],\n",
    "        high=df[\"high\"],\n",
    "        low=df[\"low\"],\n",
    "        close=df[\"close\"],\n",
    "        name=\"Candlestick\"\n",
    "    ))\n",
    "\n",
    "    # EMA\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df[\"datetime\"], y=df[\"EMA_10\"],\n",
    "        line=dict(color=\"blue\", width=2),\n",
    "        name=\"EMA_10\"\n",
    "    ))\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df[\"datetime\"], y=df[\"EMA_20\"],\n",
    "        line=dict(color=\"green\", width=2),\n",
    "        name=\"EMA_10\"\n",
    "    ))\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df[\"datetime\"], y=df[\"EMA_50\"],\n",
    "        line=dict(color=\"red\", width=2),\n",
    "        name=\"EMA_10\"\n",
    "    ))\n",
    "\n",
    "    # Buy/Sell markers\n",
    "    buy_signals = df[df[\"signal\"] == \"Buy\"]\n",
    "    sell_signals = df[df[\"signal\"] == \"Sell\"]\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=buy_signals[\"datetime\"],\n",
    "        y=buy_signals[\"close\"],\n",
    "        mode=\"markers\",\n",
    "        marker=dict(color=\"green\", size=10, symbol=\"triangle-up\"),\n",
    "        name=\"Buy\"\n",
    "    ))\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=sell_signals[\"datetime\"],\n",
    "        y=sell_signals[\"close\"],\n",
    "        mode=\"markers\",\n",
    "        marker=dict(color=\"red\", size=10, symbol=\"triangle-down\"),\n",
    "        name=\"Sell\"\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(title=\"📈 Price with EMA + Signals\",\n",
    "                      xaxis_title=\"Time\", yaxis_title=\"Price\",\n",
    "                      xaxis_rangeslider_visible=False,\n",
    "                      height=600)\n",
    "    return fig\n",
    "\n",
    "def plot_rsi(df):\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=df[\"datetime\"], y=df[\"RSI\"], line=dict(color=\"blue\")))\n",
    "    fig.add_hline(y=70, line_dash=\"dash\", line_color=\"red\")\n",
    "    fig.add_hline(y=30, line_dash=\"dash\", line_color=\"green\")\n",
    "    fig.update_layout(title=\"📉 RSI\", height=300)\n",
    "    return fig\n",
    "\n",
    "while True:\n",
    "    df = load_data()\n",
    "\n",
    "    if df.empty:\n",
    "        st.warning(\"⏳ Waiting for Spark to write streaming data...\")\n",
    "    else:\n",
    "        df = compute_indicators(df)\n",
    "\n",
    "        # Plot charts\n",
    "        price_fig = plot_price_chart(df)\n",
    "        rsi_fig = plot_rsi(df)\n",
    "\n",
    "        # Layout\n",
    "        st.plotly_chart(price_fig, use_container_width=True)\n",
    "        st.plotly_chart(rsi_fig, use_container_width=True)\n",
    "\n",
    "        with st.expander(\"📄 Latest Data\"):\n",
    "            st.dataframe(df.sort_values(\"datetime\", ascending=False).tail(20))\n",
    "\n",
    "    time.sleep(REFRESH_INTERVAL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ada52d5",
   "metadata": {},
   "source": [
    "For running the visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704b25c6",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "$ streamlit run app.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f9fab9",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

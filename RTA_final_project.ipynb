{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75af87f8",
   "metadata": {},
   "source": [
    "## Real Time Analytics Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a19fbb",
   "metadata": {},
   "source": [
    "<b> CryptoStreamLab: Real-Time Analysis of Cryptocurrency Markets Using Streaming Data </b> \\\n",
    "An Exploration of Real-Time Price and Volume Analysis with Spark, Kafka, and Streamlit for Enhanced Trading Strategies "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3848fe8b",
   "metadata": {},
   "source": [
    "<b> Author:\\\n",
    "    1. Cuong Vo - 131116\\\n",
    "    2. Trang Linh Nguyen - 131036\\\n",
    "    3. Aisel Akhmedova - 131008 </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d5a1fc",
   "metadata": {},
   "source": [
    "<b> Tech Stack:\\\n",
    "    1. Spark: 3.5.0\\\n",
    "    2. Python: 3.10.12\\\n",
    "    3. OS: WSL Linux\\\n",
    "    4. Streamlit: \\\n",
    "    5. Scala: 2.12.18\\\n",
    "    6. Java OpenJDK 64-Bit Server VM: 11.0.25</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc6bbed",
   "metadata": {},
   "source": [
    "## Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9677b1",
   "metadata": {},
   "source": [
    "## Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c2d266",
   "metadata": {},
   "source": [
    "The dataset consists of real-time cryptocurrency market data streamed from Binance. Each record includes the following fields:\n",
    "\n",
    "- **Ticker**: The symbol representing the cryptocurrency pair (e.g., BTCUSDT).\n",
    "- **Timestamp**: The date and time when the data was recorded.\n",
    "- **Open**: The opening price of the cryptocurrency for the given time interval.\n",
    "- **Close**: The closing price of the cryptocurrency for the given time interval.\n",
    "- **Price**: The current price at the time of data capture.\n",
    "- **Volume**: The total trading volume of the cryptocurrency during the interval.\n",
    "\n",
    "This data enables real-time analysis of price movements and trading activity for various cryptocurrencies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393f9117",
   "metadata": {},
   "source": [
    "## Kafka Server setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce6dbb3",
   "metadata": {},
   "source": [
    "Kafka Server is created on <b>localhost:9092</b> on WSL Linux Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582b8e51",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "$ sudo systemctl daemon-reload\n",
    "$ sudo systemctl start zookeeper\n",
    "$ sudo systemctl start kafka"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209e6559",
   "metadata": {},
   "source": [
    "To check status of Kafka Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b68a70",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "$ sudo systemctl status kafka "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d5c25b",
   "metadata": {},
   "source": [
    "## Streaming Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8a2d70",
   "metadata": {},
   "source": [
    "### Create Kafka topic\n",
    "In this part, using Linux to create Kafka topic name StreamQuant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68ec7a2",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "$ cd /usr/local/kafka \n",
    "$ bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --topic StreamQuant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b0b853",
   "metadata": {},
   "source": [
    "Check for topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e5f114",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "$ bin/kafka-topics.sh --list --bootstrap-server localhost:9092"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d527df6d",
   "metadata": {},
   "source": [
    "### Create Kafka Procedure\n",
    "In this part, combined with the API key from Binance, we pull the data from Binance and send it to Kakfa producer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50058ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from binance.client import Client\n",
    "from kafka import KafkaProducer\n",
    "import json\n",
    "import time\n",
    "\n",
    "#  using API keys\n",
    "api_key = 'giuBTEvNmtfaSuPpCZfmF7uXzRYfKzk7sAwC4ezjB3KbfGLS30UnQMDxcxs15WSB'\n",
    "api_secret = 'SOmHSWFBuTa20grpf8r87c9qm9tym1oHkjktpu4mIwB9L08qvXW4W9HK7FSt1y6o'\n",
    "\n",
    "client = Client(api_key, api_secret)\n",
    "\n",
    "def get_historical_data(symbol, interval, lookback):\n",
    "    \"\"\"\n",
    "    Fetch historical data from Binance for a given symbol and interval.\n",
    "    :param symbol: The trading pair symbol (e.g., 'BTCUSDT').\n",
    "    :param interval: The time interval for the data (e.g., '1m', '5m', '1h', '1d').\n",
    "    :param lookback: The lookback period for the data (e.g., '1 day ago UTC', '1 hour ago UTC').\n",
    "    \"\"\"\n",
    "    try:\n",
    "        klines = client.get_historical_klines(symbol, interval, lookback)\n",
    "        return klines\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {symbol}: {e}\")\n",
    "        return None\n",
    "    \n",
    "producer = KafkaProducer(\n",
    "    bootstrap_servers='localhost:9092',  # Replace with your Kafka broker if different\n",
    "    value_serializer=lambda v: json.dumps(v).encode('utf-8')  # Serialize to JSON bytes\n",
    ")\n",
    "\n",
    "topic = 'StreamQuant'\n",
    "\n",
    "i = 0\n",
    "\n",
    "keys = [\"timestamp\", \"open\", \"high\", \"low\", \"close\", \"volume\"]\n",
    "\n",
    "while True:\n",
    "    i +=1\n",
    "    binance_data = get_historical_data('BTCUSDT', '1m', '1 minute ago UTC')\n",
    "    values = [int(binance_data[0][0])] + [float(x) for x in binance_data[0][1:]]\n",
    "    data_dict = dict(zip(keys, values))\n",
    "    producer.send(topic, value=data_dict)\n",
    "    print(f\"Sent {topic} - {i}: {data_dict}\")\n",
    "    time.sleep(60)  # Sleep for 1 minute before fetching the next data point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cae005f",
   "metadata": {},
   "source": [
    "## Trading Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc1ae02",
   "metadata": {},
   "source": [
    "### Create Kafka Consumer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e1de83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, DoubleType, StructField, LongType\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "spark = SparkSession.builder.appName(\"StreamQuant\").getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "schema = StructType([\n",
    "  StructField('timestamp', LongType()),\n",
    "  StructField('open', DoubleType()),\n",
    "  StructField('high', DoubleType()),\n",
    "  StructField('low', DoubleType()),\n",
    "  StructField('close', DoubleType()),\n",
    "  StructField('volume', DoubleType())\n",
    "])\n",
    "\n",
    "df_raw = spark.readStream.format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"localhost:9092\") \\\n",
    "    .option(\"subscribe\", \"StreamQuant\") \\\n",
    "    .option(\"startingOffsets\", \"latest\") \\\n",
    "    .load()\n",
    "\n",
    "df_raw = df_raw.selectExpr(\"CAST(value AS STRING)\")\n",
    "\n",
    "df_raw = df_raw.withColumn(\"value\", F.from_json(df_raw.value, schema))\\\n",
    "    .select(\"value.*\")  \n",
    "\n",
    "df_raw = df_raw.withColumn(\"datetime\", F.from_unixtime(F.col(\"timestamp\") / 1000))\n",
    "\n",
    "df_raw.writeStream \\\n",
    " .format(\"parquet\") \\\n",
    " .option(\"path\", \"/tmp/stream_output/\") \\\n",
    " .option(\"checkpointLocation\", \"/tmp/stream_checkpoint/\") \\\n",
    " .outputMode(\"append\") \\\n",
    " .start() \\\n",
    " .awaitTermination()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1cf767",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce067785",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "st.title(\"ðŸ“ˆ Live Trading Feed (EMA/RSI Ready)\")\n",
    "\n",
    "DATA_DIR = \"/tmp/stream_output/\"\n",
    "\n",
    "# Refresh every 5 seconds\n",
    "REFRESH_INTERVAL = 65\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
